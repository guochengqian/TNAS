diff --git a/cfgs/default.yaml b/cfgs/default.yaml
index d6c043a..418ad4a 100644
--- a/cfgs/default.yaml
+++ b/cfgs/default.yaml
@@ -16,7 +16,5 @@ log_dir: ./output/search/
 print_freq: 100
 
 wandb:
-  entity: null
-  use_wandb: False
-  project: NATS-Bench
-
+  use_wandb: True 
+  project: NATS-Bench
\ No newline at end of file
diff --git a/cfgs/search_cell/default.yaml b/cfgs/search_cell/default.yaml
index d5e61fc..d937992 100644
--- a/cfgs/search_cell/default.yaml
+++ b/cfgs/search_cell/default.yaml
@@ -15,7 +15,6 @@ drop_path_rate: null
 
 
 criterion: Softmax
-
 LR: 0.025
 
 # optimizer config.
diff --git a/env_install.sh b/env_install.sh
index c8a9f8e..d9bd3ec 100644
--- a/env_install.sh
+++ b/env_install.sh
@@ -1,36 +1,27 @@
 #!/usr/bin/env bash
-# make sure command is : source env_install.sh
-
-# install anaconda3.
-# cd ~/
-# wget https://repo.anaconda.com/archive/Anaconda3-2019.07-Linux-x86_64.sh
-# bash Anaconda3-2019.07-Linux-x86_64.sh
-
-# module load, uncommet if using local machine
-#module purge
-#module load gcc
-#module load cuda/10.1.105
-
-# make sure your annaconda3 is added to bashrc
-#source activate
+# install miniconda3 if not installed yet. 
+#wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 
+#bash Miniconda3-latest-Linux-x86_64.sh  
 #source ~/.bashrc
 
+# module load, only necessary for slurm
+module purge
+module load gcc
+module load cuda/10.1.105
+
 conda create --name tnas 
 conda activate tnas
 conda install -y pytorch=1.7.0 torchvision cudatoolkit=10.1 python=3.6.8 Pillow=6.1 -c pytorch 
 
 # install useful modules
 pip install tqdm graphviz tensorboard wandb easydict multimethod nats-bench gdown
-
 python setup.py install  # install xautodl 
 
-
 # download the NATS-Bench file
 export TORCH_HOME=~/.torch
 mkdir ~/.torch
 cd $TORCH_HOME
 gdown https://drive.google.com/uc?id=17_saCsj_krKjlCBLOJEpNtzPXArMCqxU
 gdown https://drive.google.com/uc?id=1scOMTUwcQhAMa_IMedp9lTzwmgqHLGgA
-
 tar -xf NATS-tss-v1_0-3ffb9-simple.tar
-tar -xf NATS-sss-v1_0-50262-simple.tar
+tar -xf NATS-sss-v1_0-50262-simple.tar
\ No newline at end of file
diff --git a/exps/NAS-Bench-201-algos/TNAS.py b/exps/NAS-Bench-201-algos/TNAS.py
index 6b7ffdf..bcfd06f 100644
--- a/exps/NAS-Bench-201-algos/TNAS.py
+++ b/exps/NAS-Bench-201-algos/TNAS.py
@@ -3,10 +3,8 @@ Copyright 2021@Guocheng Qian
 File Description: PyTorch Implementation of TNAS on NAS-BENCH-201 dataset
 '''
 ######################################################################################
-# python exps/NAS-Bench-201-algos/TNAS.py --cfg cfgs/search_darts/tnas.yaml wandb.entity=xxx wandb.use_wandb=True
+# python exps/NAS-Bench-201-algos/TNAS.py --cfg cfgs/search_darts/tnas.yaml
 ######################################################################################
-
-
 import os, sys, time, random, argparse, json
 import itertools
 from collections import Iterable
@@ -24,7 +22,7 @@ from xautodl.procedures import (
     save_checkpoint
 )
 from xautodl.utils import count_parameters_in_MB, obtain_accuracy
-from xautodl.log_utils import AverageMeter, time_string, convert_secs2time
+from xautodl.log_utils import AverageMeter
 from xautodl.models import get_cell_based_tiny_net, get_search_spaces
 
 sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
@@ -392,7 +390,6 @@ def main(config):
     # check whether edge is single path or not?
     model_flag, normal_flag, reduce_flag = check_single_path_model(supernet)
 
-    # TODO: here, has to percell at first. 
     alphas = ['reduce', 'normal']
     for cell in alphas:
         edge_flag = normal_flag if cell == 'normal' else reduce_flag
@@ -554,23 +551,21 @@ if __name__ == "__main__":
     tags = [config.search_space,
             config.data.dataset,
             config.algo,
-            f'N{config.model.N}', f'C{config.model.C}',
+            # f'N{config.model.N}', f'C{config.model.C}',
+            f'd_a{config.d_a}', f'd_o{config.d_o}',
+            f'order_{config.order}',
             f'WE{config.warmup_epochs}', f'WBS{config.warmup_batch_size}',
             f'DE{config.decision_epochs}', f'BS{config.train_batch_size}',
             f'LR{config.LR}',
-            f'{config.metric}', f'd_a{config.d_a}', f'd_o{config.d_o}',
-            f'order_{config.order}'
+            f'{config.metric}', 
+            f'Seed{config.rand_seed}'
             ]
     if config.re_init:
         tags.append('reinit')
     if config.group:
         tags.append('group')
-    tags.append(f'Seed{config.rand_seed}')
     generate_exp_directory(config, tags)
     config.wandb.tags = tags
-    # else:  # resume from the existing ckpt and reuse the folder.
-    #    resume_exp_directory(config, config.load_path)
-    #    config.wandb.tags = ['resume']
     logger = prepare_logger(config)
     # wandb and tensorboard
     cfg_path = os.path.join(config.log_dir, "config.json")
@@ -588,5 +583,4 @@ if __name__ == "__main__":
     summary_writer = SummaryWriter(log_dir=config.log_dir)
 
     logger.log(config)
-
     main(config)
diff --git a/xautodl/datasets/get_dataset_with_transform.py b/xautodl/datasets/get_dataset_with_transform.py
index 27bdc7d..8c1a65d 100644
--- a/xautodl/datasets/get_dataset_with_transform.py
+++ b/xautodl/datasets/get_dataset_with_transform.py
@@ -255,8 +255,8 @@ def get_nas_search_loaders(
         # logger.log('Load split file from {:}'.format(split_Fpath))      # they are two disjoint groups in the original CIFAR-10 training set
         # To split data
         if debug:
-            train_split = train_split[:64]
-            valid_split = valid_split[:64]
+            train_split = train_split[:32]
+            valid_split = valid_split[:32]
         xvalid_data = deepcopy(train_data)
         if hasattr(xvalid_data, "transforms"):  # to avoid a print issue
             xvalid_data.transforms = valid_data.transform
